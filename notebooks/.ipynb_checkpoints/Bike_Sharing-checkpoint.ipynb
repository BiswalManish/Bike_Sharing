{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4647f0",
   "metadata": {},
   "source": [
    "# Part 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992684d",
   "metadata": {},
   "source": [
    "### 1.1 Buisiness Goal:  \n",
    "Model the demand for shared bikes with the available independent variables. This will help the managers to understand how exactly the demands vary with different features. They can accordingly manipulate business strategy to meet the demand levels and meet the customer's expectations. This will also highlight the demand dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd9da1",
   "metadata": {},
   "source": [
    "### 1.2 Data Citation:\n",
    "\n",
    "[1] Fanaee-T, Hadi, and Gama, Joao, \"Event labeling combining ensemble detectors and background knowledge\", Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg, doi:10.1007/s13748-013-0040-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe217a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/manish/Documents/Projects/data_science/Bike_Sharing/data/raw data/day.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a573756",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff51f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "day.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "day.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d01be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "day.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c1a6a",
   "metadata": {},
   "source": [
    "1. The data has `730` entries for each day of the year `2018` and `2019`. The data has `16` columns of which `cnt` is the `target` variable. We have to make predictions using all other variables.\n",
    "\n",
    "2. The `instant` column does not provide any useful information as it is just another indexing column.\n",
    "\n",
    "3. `dteday` column tells us the date of which the data is taken. This column can also be avoided as it will not provide any useful inference for the cnt variable\n",
    "\n",
    "4. `yr` and `mnth` can be used to describe the impact of yr and month on the cnt of bike used.\n",
    "\n",
    "5. `holiday` gives the holiday information as a binary mapping of 1:'holiday' and 0:'no_holiday'.\n",
    "\n",
    "6. `weekday` gives the start and end of the week. Here the weekday #6 represents a monday as in the calendar.\n",
    "\n",
    "7. `workingday` is also a binary mapping of 1: 'yes' and 2: 'no'.\n",
    "\n",
    "8. `temp` and `atemp` gives the temperature estimates of the particular instant(day).\n",
    "\n",
    "9. `hum` and `windspeed` gives the information of humidity and windspeed respectively.\n",
    "\n",
    "10. `casual` and `registered`  show the count of casual and registered bike sharing users for the particular day.\n",
    "\n",
    "11. `cnt` gives the total count of registered and non-registered users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fd9f1",
   "metadata": {},
   "source": [
    "##### The data doesnot have any missing values, so we can start with EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e266f02",
   "metadata": {},
   "source": [
    "# Part 2: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58599582",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['temp', 'atemp', 'hum', \n",
    "            'casual', 'registered', 'cnt', 'windspeed']\n",
    "\n",
    "cat_cols = [col for col in day.columns if col not in \n",
    "            num_cols and col != 'dteday' and col != 'instant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86abbe63",
   "metadata": {},
   "source": [
    "### 2.1 Univariate analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b6ab19",
   "metadata": {},
   "source": [
    "#### Categorical colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a55415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catplot(data, col):\n",
    "    \n",
    "    sns.catplot(kind = 'count',\n",
    "               x = col,\n",
    "               data = data,\n",
    "               palette = 'Spectral')\n",
    "    \n",
    "#     plt.savefig(f'Count plot of {col}', dpi = 500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d193db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    catplot(data = day, col = i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674d00e",
   "metadata": {},
   "source": [
    "1. From univariate analysis of the categorical columns we find that `seasons`, `yr`, `mnth` and `weekday` are almost equally distributed.\n",
    "\n",
    "2. More no. of `non-holdiday` days are there and also more no. of `workingday` is there.\n",
    "\n",
    "3. `weathersit` #1. is most frequent, i.e. `clear` or `partly cloudy`, weather conditions are most frequent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c93bab",
   "metadata": {},
   "source": [
    "#### Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numplot(data, col):\n",
    "    plt.figure(figsize = (10,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.distplot(data[col], color = 'salmon')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxenplot(data[col], color = 'teal')\n",
    "    plt.xlabel('Density')\n",
    "    plt.ylabel(f'{col}')\n",
    "    \n",
    "#     plt.savefig(f'Distribution plot for {col}', dpi = 500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddac088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    numplot(day, i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5de93a",
   "metadata": {},
   "source": [
    "1. The `atemp` column data seem to be somewhat normally distributed with two peaks @ `15` and `35` deg Celcius. Whereas the `temp` column is also similarly distributed although the two peaks are @ `10` and `30` deg Celcius. This suggests that the mean `atemp` is `5` degrees above mean `temp` in any given day. This is beacause of the `humidity`.\n",
    "\n",
    "2. Casual or non- registered users have left skewed distribution suggesting there are about `500` to `1000` `casual riders` in any given day.\n",
    "\n",
    "3. The `registered` users are mostly in the range of `4000` in any given and theu follow a normal distribution.\n",
    "\n",
    "4. Total `cnt`, which is our target varibale is mostly normally distributed with some peaks on bith side of the distribution.\n",
    "\n",
    "5. `Humidity` is right skewed suggesting mean humidity of a day is around `70%`. This also supports our temp and atemp distribution.\n",
    "\n",
    "6. `Windspeed` is slightly left skewed suggesting mean windspeed per any given day is around `10`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b844a11",
   "metadata": {},
   "source": [
    "### 2.2 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00830cb",
   "metadata": {},
   "source": [
    "#### Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d229e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looking at relationship of num cols to that of count\n",
    "g = sns.PairGrid(day[num_cols])\n",
    "g.map_upper(sns.scatterplot, color = 'teal')\n",
    "g.map_lower(sns.scatterplot, color = 'salmon')\n",
    "g.map_diag(plt.hist)\n",
    "# plt.savefig('Target vs Numerical data', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a4619",
   "metadata": {},
   "source": [
    "1. From the pair plot we can see `temp`, `atemp`, `registered` and `casual` has some linear relationship with `cnt.\n",
    "\n",
    "2. `temp` and `atemp` are linearly dependent with each other so we have to choose one for model building to avoid multicollinearity issues.\n",
    "\n",
    "3. `hum` does not show any linear relationship with `cnt`.\n",
    "\n",
    "4. `temp`, `atemp`, `registered` and `casual` have somewhat of a normal distribution. Whereas `casual` is left skewed. Also `hum` is somewhat normal with shorter tails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ea5c1",
   "metadata": {},
   "source": [
    "#### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b09e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1fd9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    plt.figure(figsize = (10,6))\n",
    "    sns.catplot(data = day,\n",
    "                kind = 'violin',\n",
    "                x = i,\n",
    "                y = 'cnt',\n",
    "                palette = 'Spectral')\n",
    "#     plt.savefig(f'Distribution of bike counts vs {i}', dpi = 500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abb6de",
   "metadata": {},
   "source": [
    "#### Plotting `cnt` with various categorical columns we find that:\n",
    "\n",
    "1. Seson has some visible impact on the bike counts. With season `3` having the highest median count followed by season `2`, `4` and `1`.\n",
    "\n",
    "2. The year `2019` has higher median bike counts than year `2018`.\n",
    "\n",
    "3. Similar to seasons the months have a similar distribution of bike counts. With highest being the month of `june`, `july` followed by fall months and leasr is observed in the months of `jan` and `feb`.\n",
    "\n",
    "4. Non holiday days have higher median count than holidays\n",
    "\n",
    "5. All weekdays have similar distribution with day `3` and `4` have slightly higher median counts.\n",
    "\n",
    "6. Working day and non working day have similar median counts with working day having higher concentration near median, whereas non-working day have smoother peaks and elongated tails.\n",
    "\n",
    "7. Weathersit `1` are more favourable for bike counts than `2` and `3`, with `3` being list favourable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cf416",
   "metadata": {},
   "source": [
    "### 2.3 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456cbd70",
   "metadata": {},
   "source": [
    "#### Bike count for different years and different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce49525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    if i != 'yr':\n",
    "        sns.catplot(kind = 'violin',\n",
    "                    data = day,\n",
    "                    x = i,\n",
    "                    y = 'cnt',\n",
    "                    col = 'yr',\n",
    "                    palette = 'Spectral' )\n",
    "#         plt.savefig('Distribution of bike counts on various {} for both years'.format(i), dpi = 500)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402d0d2",
   "metadata": {},
   "source": [
    "#### Plotting bike cnt for various categories for different years we find.\n",
    "\n",
    "1. Season has similar distribution in both years for each seasons but higher median bike counts are found for year `2019`. Also we see slightly elongated tails in individual seasons fro the year 2019.\n",
    "\n",
    "2. Months like season show similar distribution, have similar elongated tails for the yera 2019.\n",
    "\n",
    "3. Non holidays have slightly higher median counts for the years. But we see it is higher for the year 2019.\n",
    "\n",
    "4. In `2018` the highest median count is for the day `2` and slid down for the days after  `2` and also before 2. Whereas for the year `2019` the highest median count is for day `3` and day `6`. Also median count for year 2019 is higher than 2018.\n",
    "\n",
    "5. Working day and non working day have similar median count and is slightly more for the year 2019 than the year 2018.\n",
    "\n",
    "6. Weathersit `1` are most favourable in both years but the difference in count is more observable between weather sit `1` and `3` for the year 2019 than `2018`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d705a3c",
   "metadata": {},
   "source": [
    "From the above analysis we see that- `Mnth` and `season` show similar impact and they can create `multicollinearity`.  So are `temp` and `atemp`. `Weathersit`,` year` and `season` have visible `impact` on bike `count`. It seems because of increse in popularity the bike count incresed in the year 2019 than 2018. This can show the improvement in business for the company but doesnot show prediction for the bike count in a given day. So yr cannot be a predictor variable for bike count. Also we can drop the instant and dteday columns as they will not have any impact on the prediction of cnt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e22ed7b",
   "metadata": {},
   "source": [
    "# Part 3: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c407a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7737d9",
   "metadata": {},
   "source": [
    "### 3.1 MODEL PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473aa499",
   "metadata": {},
   "source": [
    " Dropping registered and casual user columns as they are redundant to the target variable, also dropping dteday and instant column as they are unnecessay for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "day.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c448ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = day.drop(['instant', 'dteday', 'casual', 'registered'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c6bca",
   "metadata": {},
   "source": [
    "### 3.1.1 Creating dummies for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6da4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_season = pd.get_dummies(df.season).rename({1 : 'spring', 2 : 'summer',\n",
    "                                              3 : 'fall', 4 :  'winter'}, axis = 1).drop(['spring'], axis =1)\n",
    "\n",
    "\n",
    "df_mnth = pd.get_dummies(df.mnth).rename({1 : 'Jan', 2 : 'Feb', 3 : 'Mar', 4 : 'Apr',\n",
    "                                            5 : 'May', 6 : 'Jun', 7 : 'Jul', 8 : 'Aug',\n",
    "                                            9 : 'Sep', 10 : 'Oct', 11 : 'Nov', 12 : 'Dec'},\n",
    "                                           axis = 1).drop(['Jan'], axis =1)\n",
    "\n",
    "\n",
    "df_weekday = pd.get_dummies(df.weekday).rename({0 : 'Tue', 1 : 'Wed', 2: 'Thu', 3: 'Fri',\n",
    "                                                4 : 'Sat', 5 : 'Sun', 6 : 'Mon'}, \n",
    "                                              axis = 1).drop(['Tue'], axis = 1)\n",
    "\n",
    "\n",
    "df_weather = pd.get_dummies(df.weathersit).rename({1 : 'Clear', 2 : 'Clody_misty',\n",
    "                                              3 : 'Rainy_snow'}, axis = 1).drop(['Clear'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d284a7c5",
   "metadata": {},
   "source": [
    "##### Dropping the redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_season, df_mnth, df_weekday, df_weather], axis = 1).drop(['season',\n",
    "                                                                'mnth', 'weekday', 'weathersit'],\n",
    "                                                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08f0a2",
   "metadata": {},
   "source": [
    "### 3.1.2 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.3,\n",
    "                                     random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce361e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a9bbf",
   "metadata": {},
   "source": [
    "### 3.1.3 Rescalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e954ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols.remove('casual')\n",
    "num_cols.remove('registered')\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[num_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dede97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescalling numerical columns\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_train[num_cols] = scaler.fit_transform(df_train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487002b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[num_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef080bef",
   "metadata": {},
   "source": [
    "### 3.1.4 Creating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91116cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(['cnt'], axis = 1), df_train['cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fdcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2adcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c3988",
   "metadata": {},
   "source": [
    "Our model preparation is done. Let us check the correlation of various independent variables and the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c7f58",
   "metadata": {},
   "source": [
    "### 3.1.5 Correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9b1fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df_train.corr()\n",
    "\n",
    "plt.figure(figsize = (25,25))\n",
    "sns.heatmap(corr, annot = True, cmap = 'Greens')\n",
    "plt.savefig('Heatmap', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23a2e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var = corr.cnt.sort_values()\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc15478",
   "metadata": {},
   "source": [
    "We can see that `Feb`,  `weathersit`, `windspeed` have high `negative` correlation and `atemp`, `temp` and `yr` have high `positive` correlation with `cnt`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849094d1",
   "metadata": {},
   "source": [
    "### 3.2 MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3730123",
   "metadata": {},
   "source": [
    "### 3.2.1 Creating a sorted variable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b2641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var = pd.DataFrame(data = var)\n",
    "var['abs_values'] = var.apply(lambda x : abs(x))\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605ad9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var = list(var['abs_values'].sort_values(ascending = False).index)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "var.remove('cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bdd80",
   "metadata": {},
   "source": [
    "### 3.2.2 Functions for building linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a linear model\n",
    "def build_linear_model(X, y):\n",
    "    \n",
    "    model = sm.OLS(y, sm.add_constant(X))\n",
    "    model = model.fit()\n",
    "#     print(model.rsquared_adj)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Checking VIF scores for independent variables\n",
    "def get_vif(X_train):\n",
    "    vif_df = pd.DataFrame()\n",
    "\n",
    "    vif_df['Features'] = X_train.columns\n",
    "    vif_df['VIF'] = [variance_inflation_factor(X_train.values, i)\n",
    "                 for i in range(X_train.shape[1])]\n",
    "\n",
    "    vif_df = vif_df.sort_values(by = 'VIF', ascending = False)\n",
    "    return vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e757bc",
   "metadata": {},
   "source": [
    "### 3.2.3 Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec064d",
   "metadata": {},
   "source": [
    "#### Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = build_linear_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab6252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model0.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d81899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model0.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400fb0b9",
   "metadata": {},
   "source": [
    "This shows that taking all the coloumsn together we get aa adjusted r2 `0.839`. But we severe multicollinearity issues. As a lot of variables have very high `p-value`\n",
    "\n",
    "We need to eliminate feature and we can do this using recurssive feature elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ecaec",
   "metadata": {},
   "source": [
    "#### Cheking the adjusted R2 vs features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdd510",
   "metadata": {},
   "source": [
    "Creating a list of list of variables, increasing the list by one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1165d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = []\n",
    "for i in range(1,len(var) + 1):\n",
    "    k = var[ : i]\n",
    "    var_list.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f8fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Adj_r2 = []\n",
    "for i in var_list:\n",
    "    model = build_linear_model(X_train[i], y_train)\n",
    "    k = round(100 * (model.rsquared_adj), 3)\n",
    "    Adj_r2.append(k)\n",
    "    \n",
    "plt.figure(figsize = (8,8))\n",
    "plt.plot(Adj_r2, color = 'C3')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Adjusted_r2')\n",
    "# plt.savefig('Adjusted_r2 vs features', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1efe48",
   "metadata": {},
   "source": [
    "We find that the adjusted r2 increases to `70%` with just 2 variables, but as we increase the no. of variables the increase in adr_r2 score increses very slowly and flattens first at 15 features @ `80%`. Then agin it increases to `85%` with addition of two more variables and flattens at `85%` even with increase invariables.\n",
    "\n",
    "This suggests that no improvement in accuracy will occur with features more than `17`. So we check for the top `15` features using `RFE`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f5f45",
   "metadata": {},
   "source": [
    "### 3.2.4 Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f79a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_vif(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eaba58",
   "metadata": {},
   "source": [
    "we see a lot of columns with high VIF and high p-values, we can eliminate them one by one or use, RFE to eliminate the ones we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209951a",
   "metadata": {},
   "source": [
    "####  Checking RFE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457497a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed168a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(estimator = lr,\n",
    "          n_features_to_select = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8d9c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RFE_ = pd.DataFrame(list(zip(X_train.columns, rfe.support_, rfe.ranking_)),\n",
    "                    columns = ['Features', 'Support', 'Ranking'])\n",
    "RFE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91298fe1",
   "metadata": {},
   "source": [
    "##### Eliminating features not supported by RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f978a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup = X_train.columns[rfe.support_]\n",
    "rej = X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc6e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[sup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323dd785",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1 = build_linear_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85442af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Model1.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe50eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_vif(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7359b7",
   "metadata": {},
   "source": [
    "We have to eliminate `Thu`, `Fri`, `Sat`, `Sun` and check again for vif and p-values in next Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a6d42",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Thu', 'Fri', 'Sat', 'Sun'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210f1eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Model2 = build_linear_model(X_train, y_train)\n",
    "print(Model2.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vif(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7681ce6e",
   "metadata": {},
   "source": [
    "We still have `workingday`, `holiday` and `Wed` with high p-values, we drop these in the next model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6550e",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['workingday', 'holiday', 'Wed'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1dbfe0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Model3 = build_linear_model(X_train, y_train)\n",
    "print(Model3.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e145fbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_vif(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49592341",
   "metadata": {},
   "source": [
    "Model 3 has statistically significant independent variables, but we still have some multicollinearity issue with hum and atemp. We eliminate these features, but since the coefficients are high for them, they seem to increase the accuracy of the model.\n",
    "\n",
    "We can choose fall and windsprred which have higher VIF and lower coefficient values or we can keep this model.\n",
    "Lets check for the accuracy and VIF score by eliminating these two features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc661a2",
   "metadata": {},
   "source": [
    "#### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model4 = build_linear_model(X_train.drop(['fall'], axis = 1), y_train)\n",
    "print(Model4.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10507e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vif(X_train.drop(['fall'], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44cbab",
   "metadata": {},
   "source": [
    "Dropping the fall column results in slight decrease of accuracy from adj_r2 score of `80.5%` in Model3 to `79.5%` in Model4 but this significantly reduces the VIF for hum and atemp from `21`, `11` to `10`, `7` respectively for Model3 and Model4.\n",
    "\n",
    "This seems to be managable and we can stop from further feature elimination. But if we eliminate the windspeed we can further reduce the VIFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5d040",
   "metadata": {},
   "source": [
    "#### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ab378",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model5 = build_linear_model(X_train.drop(['fall', 'windspeed'], axis = 1), y_train)\n",
    "print(Model5.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vif(X_train.drop(['fall', 'windspeed'], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077f2dc",
   "metadata": {},
   "source": [
    "We can use this model as the VIfs have come below 10 also the accuracy has not reduced that significantly, But the p value of the intercept has slightly increased but it is still statistically significant.\n",
    "\n",
    "So this model can be used for getting bike count using multiple linear regression model with RFE for feature elimination and VIF for tackling multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34c228",
   "metadata": {},
   "source": [
    "Thus the final model can be written as:\n",
    "\n",
    "y = 0.0868 + (.2324 * yr) +  (.7311 * atemp) + (-0.224 * hum) + (0.0675 * summer) + (0.1572 * winter) + (-0.1827 * Rainy/snow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d90c5a",
   "metadata": {},
   "source": [
    "#### Saving X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a44f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['fall', 'windspeed'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc71eba",
   "metadata": {},
   "source": [
    "#### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model0, Model1, Model2,\n",
    "          Model3, Model4, Model5]\n",
    "\n",
    "# for model in range(len(models)):\n",
    "#     fname = f'Model{model}'\n",
    "#     pickle.dump(fname, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a20db9",
   "metadata": {},
   "source": [
    "Now we can proceed to residual analysis and model training prediction and then to model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0842b3",
   "metadata": {},
   "source": [
    "### 3.3 RESIDUAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b828003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_analysis(X_train, y_train, model):\n",
    "    \n",
    "        \n",
    "    y_train_pred = model.predict(sm.add_constant(X_train))\n",
    "\n",
    "    \n",
    "    res = y_train - y_train_pred\n",
    "    \n",
    "    for i in X_train.columns:\n",
    "    \n",
    "        plt.figure(figsize = (10, 5))    \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.distplot(x = res, color = 'C3')\n",
    "    \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.scatterplot(x = X_train[i], y = res, color = 'C2')\n",
    "    \n",
    "\n",
    "        plt.savefig(f'Residual analysis for {i}', dpi = 500)\n",
    "\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9870f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# residual analysis for model5\n",
    "\n",
    "residual_analysis(X_train, y_train, Model5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683963f",
   "metadata": {},
   "source": [
    "From residual analysis we can see that the errors are normally distributed and the distribution of errors with respect to each variable is random. That is the residuals show homscadasticity. \n",
    "\n",
    "In other words the variance in independent variables throughout the data domain doesnot affect the residuals' variance in the domain of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cda758",
   "metadata": {},
   "source": [
    "### 3.4 MODEL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescalling test data\n",
    "df_test[num_cols] = scaler.transform(df_test[num_cols])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc837887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X_test and y_test\n",
    "X_test = df_test[X_train.columns]\n",
    "y_test = df_test.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prediction and evaluation\n",
    "def model_eval(X_test, y_test, model):\n",
    "    \n",
    "    y_test_pred = model.predict(sm.add_constant(X_test))\n",
    "        \n",
    "    r2 = r2_score(y_true = y_test,\n",
    "                  y_pred = y_test_pred)\n",
    "    \n",
    "    mse = mean_squared_error(y_true = y_test,\n",
    "                             y_pred = y_test_pred )\n",
    "    \n",
    "    plt.scatter(x = y_test, y = y_test_pred, color = 'C1')\n",
    "    plt.xlabel('y_test')\n",
    "    plt.ylabel('y_test_pred')\n",
    "    plt.title('y_test vs y_pred')\n",
    "#     plt.savefig('y_test vs y_pred.png', dpi = 500)\n",
    "    \n",
    "    \n",
    "    print('\\nCoeff of determination, r2: {}'.format(r2))\n",
    "    print('\\nMean squared error, mse: {}'.format(mse))\n",
    "    \n",
    "    return r2, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b35b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model5.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(X_test, y_test, Model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b70313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
